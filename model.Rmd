---
title: "Model"
author: "Tate Huffman"
date: "4/24/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
library(magrittr)
library(gt)
library(haven)
library(tidyverse)
library(tidymodels)
```

## Building the Model

We want to examine the effect of pitch sequencing on pitcher success - or to see whether it has a substantial effect at all. We load in our data, and create new variables, using code from previous Rmarkdown documents. 

```{r load_data, cache = TRUE}

# copying and altering most of code from explore.Rmd

load_files <- function(path) { 
  files <- dir(path, pattern = "data_\\d{4}.csv", full.names = TRUE)
  bind_rows(map_df(files, read_csv))
}

pitches <- load_files("data")

# creates pitch sequence

pitches %<>% mutate(pitch_seq = ifelse(!(pitch_number == 1 |
                                        is.na(pitch_type) |
                                        is.na(lag(pitch_type))), 
                                      paste0(lag(pitch_type), pitch_type),
                                      NA))

# adds in batter names, manually inputting unknown players

players <- read_csv("players.csv", col_types = cols()) %>% 
  select(mlb_id, mlb_name)

pitches %<>% 
  left_join(players, by = c("batter" = "mlb_id")) %>% 
  rename(batter_name = "mlb_name", pitcher_name = "player_name") %>% 
  mutate(batter_name = case_when(batter == 121347 ~ "Alex Rodriguez",
                                 batter == 116338 ~ "Torii Hunter",
                                 batter == 133380 ~ "Aramis Ramirez",
                                 batter == 120074 ~ "David Ortiz",
                                 batter == 150229 ~ "A.J. Pierzynski",
                                 batter == 218596 ~ "Tim Hudson",
                                 batter == 150359 ~ "A.J. Burnett",
                                 batter == 150302 ~ "Jason Marquis",
                                 batter == 329092 ~ "Randy Choate",
                                 batter == 279824 ~ "Mark Buehrle",
                                 batter == 605228 ~ "Jose Fernandez",
                                 batter == 115629 ~ "LaTroy Hawkins",
                                 TRUE ~ as.character(batter_name)))

# adding more pitch info in comparison to previous pitches

pitches %<>% 
  mutate(speed_diff = ifelse(!(pitch_number == 1 | 
                                 is.na(pitch_type) | 
                                 is.na(lag(pitch_type))),
                             release_speed - lag(release_speed), NA),
         loc_diff_x = ifelse(!(pitch_number == 1 | 
                                 is.na(pitch_type) | 
                                 is.na(lag(pitch_type))),
                             plate_x - lag(plate_x), NA),
         loc_diff_z = ifelse(!(pitch_number == 1 | 
                                 is.na(pitch_type) | 
                                 is.na(lag(pitch_type))),
                             plate_z - lag(plate_z), NA),
         loc_diff_total = ifelse(!(pitch_number == 1 | 
                                     is.na(pitch_type) | 
                                     is.na(lag(pitch_type))),
                                 sqrt(loc_diff_x^2 + loc_diff_z^2), NA))

# create binary indicator for whether pitcher was the starter
# also creates variable for score difference
# makes top/bottom of an inning a binary variable
# does the same for runners on base
# we also create an indicator for whether the pitcher/batter are same-handed
# we also turn the pitch sequences into factors here using fct_lump()

pitches %<>% 
  group_by(game_pk, inning_topbot) %>% 
  mutate(starter = ifelse(pitcher_name == first(pitcher_name), 1, 0)) %>% 
  ungroup() %>% 
  mutate(score_diff = fld_score - bat_score,
         inning_topbot = ifelse(inning_topbot == "Top", 1, 0),
         on_3b = ifelse(is.na(on_3b), 0, 1),
         on_2b = ifelse(is.na(on_2b), 0, 1),
         on_1b = ifelse(is.na(on_1b), 0, 1),
         same_handed = ifelse(stand == p_throws, 1, 0),
         stand = as_factor(stand),
         p_throws = as_factor(p_throws),
         pitch_seq = as_factor(pitch_seq), 
         pitch_seq = fct_lump(pitch_seq, prop = 0.02))

# creates a smaller sample dataset w/ data from random 1,000 games

pitch_sample <- pitches %>% 
  filter(game_pk %in% c(sample(pull(select(pitches, game_pk)), 1000)))

# creating new tibbles with this data
# focusing on sequences and outcomes means we focus only on the end result of
# PAs featuring at least 2 pitches
# so this analysis definitely has holes, given that it's ignoring lots of data
# but as a rough, preliminary analysis, hopefully it holds up
# a wOBA denominator of 1 is essentially all plays except HBP and sacrifices

pitches_mod <- pitches %>%
  filter(!is.na(pitch_seq), woba_denom == 1)

pitch_sample_mod <- pitch_sample %>% 
  filter(!is.na(pitch_seq), woba_denom == 1)

```

In general, we want to create a model to predict weighted on-base average (wOBA - a measurement of overall offensive performance) from the available data, and to see the degree to which sequencing affects these predictions. To do this, we'll create several models, which we'll save as `formula` objects in R.

```{r model_prep}

# most, if not all, of this code comes from PPBDS

# this model predicts wOBA from pitch sequence

seq_form <- formula(woba_value ~ pitch_seq)

# this model adjusts the above to incorporate handedness of batter and pitcher
# including an interaction term for same-handedness
# also includes variable for whether player is a starter

matchup_form <- formula(woba_value ~ pitch_seq * same_handed + 
                          stand + p_throws + starter)

# this model includes contextual information
# specifically, count, outs, inning, baserunners, and score differential

context_form <- update(matchup_form, ~ . + balls + strikes + outs_when_up +
                         on_3b + on_2b + on_1b + inning + inning_topbot)

# this model includes other information about the pitch
# specifically, how it compares to the previous one

detailed_form <- update(context_form, ~ . + release_speed + pfx_x + pfx_z + 
                          plate_x + plate_z + speed_diff + 
                          loc_diff_x + loc_diff_z)

# here, we combine all these models into a single tibble

pitch_formulas <- tibble(formula = c(seq_form,
                                     matchup_form,
                                     context_form,
                                     detailed_form),
                         group = c("Sequence model",
                                   "Matchup model",
                                   "Context model",
                                   "Detailed model"))

# create specification for linear regression

lm_spec <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression") 

```

Importantly, we also split the data into train and test sets - these are subsets of the thousand-game subset of all the data, but it's still large enough that we're comfortable with the model creation process.

```{r train_test}

# split model into train and test sets

set.seed(1005)

pitch_sample_split <- initial_split(pitch_sample_mod, prop = 0.8)
pitch_sample_train <- training(pitch_sample_split)
pitch_sample_test <- testing(pitch_sample_split)

```

We use cross-validation to compare and analyze the different models.

```{r cv}

# creates 5 folds for cross-validation

set.seed(1005)

pitch_sample_folds <- pitch_sample_train %>%
  vfold_cv(v = 5)

# uses PPBDS for pretty much all of this
# particularly, we map the fit_resamples() function to each formula

folds_metrics <- pitch_formulas %>%
  mutate(metrics = map(formula, 
                       ~ fit_resamples(lm_spec, 
                                       preprocessor = .,
                                       resamples = pitch_sample_folds) %>%
                         collect_metrics()))

# now let's check out our results!

folds_metrics %>%
  mutate(mean_rmse = map_dbl(metrics, 
                             ~ filter(., .metric == "rmse") %>% pull(mean)),
         se_rmse = map_dbl(metrics, 
                           ~ filter(., .metric == "rmse") %>% pull(std_err))) %>%
  select(group, mean_rmse, se_rmse) %>% 
  gt()

```

From our initial cross-validation process on our test set, we see that as we add more variables, our MSE improves. 
