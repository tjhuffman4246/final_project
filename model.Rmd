---
title: "Model"
author: "Tate Huffman"
date: "4/24/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
library(magrittr)
library(gt)
library(haven)
library(tidyverse)
library(tidymodels)
```

## Building the Model

We want to examine the effect of pitch sequencing on pitcher success - or to see whether it has a substantial effect at all. We load in our data, and create new variables, using code from previous Rmarkdown documents. 

```{r load_data, cache = TRUE}

# copying and altering most of code from explore.Rmd

load_files <- function(path) { 
  files <- dir(path, pattern = "data_\\d{4}.csv", full.names = TRUE)
  bind_rows(map_df(files, read_csv))
}

pitches <- load_files("data")

# creates pitch sequence

pitches %<>% mutate(pitch_seq = ifelse(!(pitch_number == 1 |
                                        is.na(pitch_type) |
                                        is.na(lag(pitch_type))), 
                                      paste0(lag(pitch_type), pitch_type),
                                      NA))

# adds in batter names, manually inputting unknown players

players <- read_csv("data/players.csv", col_types = cols()) %>% 
  select(mlb_id, mlb_name)

pitches %<>% 
  left_join(players, by = c("batter" = "mlb_id")) %>% 
  rename(batter_name = "mlb_name", pitcher_name = "player_name") %>% 
  mutate(batter_name = case_when(batter == 121347 ~ "Alex Rodriguez",
                                 batter == 116338 ~ "Torii Hunter",
                                 batter == 133380 ~ "Aramis Ramirez",
                                 batter == 120074 ~ "David Ortiz",
                                 batter == 150229 ~ "A.J. Pierzynski",
                                 batter == 218596 ~ "Tim Hudson",
                                 batter == 150359 ~ "A.J. Burnett",
                                 batter == 150302 ~ "Jason Marquis",
                                 batter == 329092 ~ "Randy Choate",
                                 batter == 279824 ~ "Mark Buehrle",
                                 batter == 605228 ~ "Jose Fernandez",
                                 batter == 115629 ~ "LaTroy Hawkins",
                                 TRUE ~ as.character(batter_name)))

# adding more pitch info in comparison to previous pitches

pitches %<>% 
  mutate(speed_diff = ifelse(!(pitch_number == 1 | 
                                 is.na(pitch_type) | 
                                 is.na(lag(pitch_type))),
                             release_speed - lag(release_speed), NA),
         loc_diff_x = ifelse(!(pitch_number == 1 | 
                                 is.na(pitch_type) | 
                                 is.na(lag(pitch_type))),
                             plate_x - lag(plate_x), NA),
         loc_diff_z = ifelse(!(pitch_number == 1 | 
                                 is.na(pitch_type) | 
                                 is.na(lag(pitch_type))),
                             plate_z - lag(plate_z), NA),
         loc_diff_total = ifelse(!(pitch_number == 1 | 
                                     is.na(pitch_type) | 
                                     is.na(lag(pitch_type))),
                                 sqrt(loc_diff_x^2 + loc_diff_z^2), NA))

# create binary indicator for whether pitcher was the starter
# also creates variable for score difference
# makes top/bottom of an inning a binary variable
# does the same for runners on base
# we also create an indicator for whether the pitcher/batter are same-handed
# we also turn the pitch sequences into factors here using fct_lump()
# does the same thing with pitches themselves

pitches %<>% 
  group_by(game_pk, inning_topbot) %>% 
  mutate(starter = ifelse(pitcher_name == first(pitcher_name), 1, 0)) %>% 
  ungroup() %>% 
  mutate(score_diff = fld_score - bat_score,
         inning_topbot = ifelse(inning_topbot == "Top", 1, 0),
         on_3b = ifelse(is.na(on_3b), 0, 1),
         on_2b = ifelse(is.na(on_2b), 0, 1),
         on_1b = ifelse(is.na(on_1b), 0, 1),
         same_handed = ifelse(stand == p_throws, 1, 0),
         stand = as_factor(stand),
         p_throws = as_factor(p_throws),
         pitch_seq = as_factor(pitch_seq), 
         pitch_seq = fct_lump(pitch_seq, prop = 0.02),
         pitch_type = as_factor(pitch_type), 
         pitch_type = fct_lump(pitch_type, prop = 0.02))

# we do more factor work with the description of different events
# grouping into ball, called strike, swinging strike, foul, and in play
# we create vectors categorizing each of these
# and then we mutate our tibble of pitches

ball <- c("ball", "blocked_ball", "intent_ball", "hit_by_pitch", "pitchout")
strike <- c("called_strike", "swinging_strike", "swinging_strike_blocked", 
            "missed_bunt", "swinging_pitchout", "foul", "foul_bunt", 
            "foul_tip", "foul_pitchout", "bunt_foul_tip")
in_play <- c("hit_into_play", "hit_into_play_no_out", "hit_into_play_score",
             "pitchout_hit_into_play_score")

pitches %<>% 
  mutate(description = case_when(description %in% ball ~ "ball",
                                 description %in% strike ~ "strike", 
                                 description %in% in_play ~ "in_play",
                                 TRUE ~ as.character(description)),
         description = as_factor(description))

# creates a smaller sample dataset w/ data from random 1,000 games

set.seed(1005)

pitch_sample <- pitches %>% 
  filter(game_pk %in% c(sample(pull(select(pitches, game_pk)), 1000)))

# creating new tibbles with this data
# focusing on sequences and outcomes means we focus only on the end result of
# PAs featuring at least 2 pitches
# so this analysis definitely has holes, given that it's ignoring lots of data
# but as a rough, preliminary analysis, hopefully it holds up
# a wOBA denominator of 1 is essentially all plays except HBP and sacrifices

pitches_mod <- pitches %>%
#  filter(!is.na(pitch_seq), woba_denom == 1)
  filter(!is.na(pitch_seq))

pitch_sample_mod <- pitch_sample %>% 
#  filter(!is.na(pitch_seq), woba_denom == 1)
  filter(!is.na(pitch_seq))

```

In general, we want to create a model to predict pitch outcome from the available data, and to see the degree to which sequencing affects these predictions. To do this, we'll create several models, which we'll save as `formula` objects in R.

```{r model_prep}

# most, if not all, of this code comes from PPBDS

# this model predicts wOBA from pitch sequence

# seq_form <- formula(woba_value ~ pitch_seq)

# instead, our formula will predict outcome, not wOBA

seq_form <- formula(description ~ pitch_seq)

# this model predicts pitch outcome using pitch type and sequnce
# this will see the effect that sequencing has beyond the pitch type

pitch_form <- update(seq_form, ~ . + pitch_type)

# this model adjusts the above to incorporate handedness of batter and pitcher
# including an interaction term for same-handedness
# also includes variable for whether player is a starter

matchup_form <- formula(description ~ pitch_seq + pitch_type * same_handed + 
                          stand + p_throws + starter)

# this model includes contextual information
# specifically, count, outs, inning, baserunners, and score differential

context_form <- update(matchup_form, ~ . + balls + strikes + outs_when_up +
                         on_3b + on_2b + on_1b + inning + inning_topbot)

# this model includes other information about the pitch
# specifically, how it compares to the previous one

detailed_form <- update(context_form, ~ . + release_speed + pfx_x + pfx_z + 
                          plate_x + plate_z + speed_diff + 
                          loc_diff_x + loc_diff_z)

# here, we combine all these models into a single tibble

pitch_formulas <- tibble(formula = c(seq_form,
                                     pitch_form,
                                     matchup_form,
                                     context_form,
                                     detailed_form),
                         group = c("Sequence model",
                                   "Pitch type model",
                                   "Matchup model",
                                   "Context model",
                                   "Detailed model"))

# create specification for classification

rf_spec <- rand_forest() %>%
  set_engine("randomForest") %>%
  set_mode("classification") 

```

Importantly, we also split the data into train and test sets - these are subsets of the thousand-game subset of all the data, but it's still large enough that we're comfortable with the model creation process.

```{r train_test}

# split model into train and test sets
# first cleans data to exclude NA values

pitch_sample_mod %<>% 
  filter(!is.na(release_speed & pfx_x & pfx_z & plate_x & plate_z &
                  speed_diff & loc_diff_x & loc_diff_z))

set.seed(1005)

pitch_sample_split <- initial_split(pitch_sample_mod, prop = 0.8)
pitch_sample_train <- training(pitch_sample_split)
pitch_sample_test <- testing(pitch_sample_split)

```

```{r run_models}

# more PPBDS code
# cross-validation w/ RF took an incredible amount of time
# and data is big enough that CV isn't as important

fit_rf_split <- function(formula, train, test) {
  rf_spec %>%
    fit(formula, data = train) %>%
    predict(new_data = test) %>%
    bind_cols(test)
}

pitch_sample_test_preds <- pitch_formulas %>%
  mutate(preds = map(formula, ~ fit_rf_split(., pitch_sample_train, 
                                             pitch_sample_test))) %>%
  unnest(preds)

pitch_sample_test_preds %>% 
  group_by(group) %>% 
  accuracy(truth = description, estimate = .pred_class) %>% 
  gt()

```




We use cross-validation to compare and analyze the different models.

```{r cv, eval = FALSE}

#############
# this code used when doing linear regression, not classification
#############

# creates 5 folds for cross-validation

#set.seed(1005)

#pitch_sample_folds <- pitch_sample_train %>%
#  vfold_cv(v = 5)

# uses PPBDS for pretty much all of this
# particularly, we map the fit_resamples() function to each formula

#folds_metrics <- pitch_formulas %>%
#  mutate(metrics = map(formula, 
#                       ~ fit_resamples(rf_spec, 
#                                       preprocessor = .,
#                                       resamples = pitch_sample_folds) %>%
#                         collect_metrics()))

# now let's check out our results!

# folds_metrics %>%
#  mutate(mean_acc = map_dbl(metrics, 
#                             ~ filter(., .metric == "accuracy") %>% 
#                              pull(mean)),
#         se_acc = map_dbl(metrics, 
#                           ~ filter(., .metric == "accuracy") %>% 
#                            pull(std_err))) %>%
#  select(group, mean_acc, se_acc) %>% 
#  gt()

```

From our initial cross-validation process on our test set, we see that as we add more variables, our MSE improves, though our results are divided into two similar groups - there's little difference between the basic sequence-based model and the model including matchups, and while both the context-inclusive and detailed models do better than these first two, the detailed model does only slightly better than the context one. To decide between these latter two models, we'll fit them on the test set.

```{r last_fit}

# uses last_fit() function to calculate the final fit of these two models

context_final_fit <- last_fit(rf_spec, context_form, split = pitch_sample_split)
detailed_final_fit <- last_fit(rf_spec, detailed_form, split = pitch_sample_split)

# now we inspect and compare the metrics to decide on our final model

context_final_fit$.metrics[[1]] %>% 
  gt()

detailed_final_fit$.metrics[[1]] %>% 
  gt()

```

From these two models, we see that 


